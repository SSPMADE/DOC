<!DOCTYPE html>
<html>
	<head>
		<meta charset="utf-8">
		<title>ML Examples</title>
		<link type="text/css" rel="stylesheet" href="../../page.css" />
	</head>

<body>

<!-- -->
<h1>Machine Learning</h1>
Learning is Looping<br>
An ML model is Trained by Looping over data multiple times.<br>

For each iteration, the Weight Values are adjusted.<br>

Training is complete when the iterations fails to Reduce the Cost.<br><br>

Train me to find the line of best fit:<br>

100 times 200 times 300 times 500 times<br>

Try it Yourself »<br>

Gradient Descent<br>
Gradient Descent is a popular algorithm for solving AI problems.<br>

A simple Linear Regression Model can be used to demonstrate a gradient descent.<br><br><br>

The goal of a linear regression is to fit a linear graph to a set of (x,y) points. This can be solved with a math formula. But a Machine Learning Algorithm can also solve this.<br><br>

This is what the example above does.<br>

It starts with a scatter plot and a linear model (y = wx + b).<br>

Then it trains the model to find a line that fits the plot. This is done by altering the weight (slope) and the bias (intercept) of the line.<br>

Below is the code for a Trainer Object that can solve this problem (and many other problems).<br>

A Trainer Object<br>
Create a Trainer object that can take any number of (x,y) values in two arrays (xArr,yArr).<br>

Set weight to zero and the bias to 1.<br>

A learning constant (learnc) has to be set, and a cost variable must be defined:<br>

Example
<xmp>
function Trainer(xArray, yArray) {
  this.xArr = xArray;
  this.yArr = yArray;
  this.points = this.xArr.length;
  this.learnc = 0.00001;
  this.weight = 0;
  this.bias = 1;
  this.cost;
</xmp>  
Cost Function<br>
A standard way to solve a regression problem is with an "Cost Function" that measures how good the solution is.<br>

The function uses the weight and bias from the model (y = wx + b) and returns an error, based on how well the line fits a plot.<br>

The way to compute this error is to loop through all (x,y) points in the plot, and sum the square distances between the y value of each point and the line.<br>

The most conventional way is to square the distances (to ensure positive values) and to make the error function differentiable.
<xmp>
this.costError = function() {
  total = 0;
  for (let i = 0; i < this.points; i++) {
    total += (this.yArr[i] - (this.weight * this.xArr[i] + this.bias)) **2;
  }
  return total / this.points;
}
</xmp>
Another name for the Cost Function is Error Function.<br>

The formula used in the function is actually this:<br>

Formula<br>
E is the error (cost)<br>
N is the total number of observations (points)<br>
y is the value (label) of each observation<br>
x is the value (feature) of each observation<br>
m is the slope (weight)<br>
b is intercept (bias)<br>
mx + b is the prediction<br>
1/N * N∑1 is the squared mean value<br>
The Train Function<br>
We will now run a gradient descent.<br>

The gradient descent algorithm should walk the cost function towards the best line.<br>

Each iteration should update both m and b towards a line with a lower cost (error).<br>

To do that, we add a train function that loops over all the data many times:
<xmp>
this.train = function(iter) {
  for (let i = 0; i < iter; i++) {
    this.updateWeights();
  }
  this.cost = this.costError();
}
</xmp>
An Update Weights Function
The train function above should update the weights and biases in each iteration.

The direction to move is calculated using two partial derivatives:
<xmp>
this.updateWeights = function() {
  let wx;
  let w_deriv = 0;
  let b_deriv = 0;
  for (let i = 0; i < this.points; i++) {
    wx = this.yArr[i] - (this.weight * this.xArr[i] + this.bias);
    w_deriv += -2 * wx * this.xArr[i];
    b_deriv += -2 * wx;
  }
  this.weight -= (w_deriv / this.points) * this.learnc;
  this.bias -= (b_deriv / this.points) * this.learnc;
}
</xmp>
Create Your Own Library<br>
Library Code:
<xmp>
//*** myailib.js ****
function Trainer(xArray, yArray) {
  this.xArr = xArray;
  this.yArr = yArray;
  this.points = this.xArr.length;
  this.learnc = 0.00001;
  this.weight = 0;
  this.bias = 1;
  this.cost;

// Cost Function
this.costError = function() {
  total = 0;
  for (let i = 0; i < this.points; i++) {
    total += (this.yArr[i] - (this.weight * this.xArr[i] + this.bias)) **2;
  }
  return total / this.points;
}

// Train Function
this.train = function(iter) {
  for (let i = 0; i < iter; i++) {
    this.updateWeights();
  }
  this.cost = this.costError();
}

// Update Weights Function
this.updateWeights = function() {
  let wx;
  let w_deriv = 0;
  let b_deriv = 0;
  for (let i = 0; i < this.points; i++) {
    wx = this.yArr[i] - (this.weight * this.xArr[i] + this.bias);
    w_deriv += -2 * wx * this.xArr[i];
    b_deriv += -2 * wx;
  }
  this.weight -= (w_deriv / this.points) * this.learnc;
  this.bias -= (b_deriv / this.points) * this.learnc;
}

} // End Trainer Object
</xmp>
Now you can include the library in HTML:<br>
<xmp>
<!DOCTYPE html>

<html>
<script src="myailib.js"></script>
<script src="plotly-latest.min.js"></script>
<body>

<div id="myPlot" width="400px" height="400px" style="width:100%;max-width:400px;border:1px solid black"></div>

<p>Train me to find the line of best fit:</p>
<p>
<button onclick="train(100)">100 times</button>
<button onclick="train(200)">200 times</button>
<button onclick="train(300)">300 times</button>
<button onclick="train(500)">500 times</button>
</p>

<div id="demo"></div>
<script>

// Create a Trainer Object
const xArray = [32,53,61,47,59,55,52,39,48,52,45,54,44,58,56,48,44,60];
const yArray = [31,68,62,71,87,78,79,59,75,71,55,82,62,75,81,60,82,97];

let myTrainer = new Trainer(xArray, yArray);

// Generate values
let weight = 0.1 
let xValues = [];
let yValues = [];
for (let x = 0; x <= 100; x += 10) {
  yValues.push(x*weight);
  xValues.push(x);
}

let data = [
  {x:xArray, y:yArray, mode:"markers"},
  {x:xValues, y:yValues, mode:"lines"}
];

// Define Layout
const layout = {
  xaxis: {range: [0,100], title: "Square Meters"},
  yaxis: {range: [0,100], title: "Price in Millions"},
  title: "House Prices vs. Size"}
;

// Display using Plotly
Plotly.newPlot("myPlot", data, layout);

function train(iter) {
  myTrainer.train(iter);
  // Display Guessed Results
  document.getElementById("demo").innerHTML = 
  "<p>Slope: " + myTrainer.weight.toFixed(2) + "</p>" +
  "<p>Bias:  " + myTrainer.bias.toFixed(2) + "</p>" +
  "<p>Cost:  " + myTrainer.cost.toFixed(2);

let xValues = [];
let yValues = [];
for (let x = 0; x <= 100; x += 10) {
  yValues.push(x*myTrainer.weight);
  xValues.push(x);
}
data = [
  {x:xArray, y:yArray, mode:"markers"},
  {x:xValues, y:yValues, mode:"lines"}
];

Plotly.newPlot("myPlot", data, layout);
}

</script>

</body>
</html>
</xmp>
Live demo<br>
<iframe src="ML-LearningEg.html" style="position: relative;border: 0px;left: 0px;width: 100%;height: 700px;overflow: auto;"></iframe>
<br><a href="ML-LearningEg.html">View Example</a><br>
<!-- -->


</body>
</html>
